[{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp; if i \\gt len(input) \\ i + 1 \u0026amp; if input[i] = x \\ \\brace \u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp; if i \\gt len(input) \\ i + 1 \u0026amp; if input[i] = x \\ \\brace \u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp; if i \\gt len(input) \\ i + 1 \u0026amp; if input[i] = x \\ \\brace \u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace if i \\gt len(input) \\ i + 1 \u0026amp; if input[i] = x \\ \\brace \u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp; if i \\gt len(input) \\ i + 1 \u0026amp; if input[i] = x \\ \\brace \u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ i + 1 \u0026amp; if input[i] = x \\ \\brace \u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ i + 1 \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ i + 1 \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\} i + 1 \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ i + 1 \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ {i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ \\mbox{i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ \\mbox{i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ \u0026amp;\\mbox{i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ \\mbox{i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ \\mbox{i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ \\{i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ \\{i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \\\\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\{i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \\\\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\{i + 1} \u0026amp;\u0026amp; if input[i] = x \\\\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ {i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\ \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ {i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\ \u0026amp; \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ {i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\ \u0026amp; \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ \u0026amp; {i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\ \u0026amp; \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ \u0026amp; {i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \u0026amp; \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\ \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ {i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\ {i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\newline \\ {i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\newline {i + 1} \u0026amp;\u0026amp; if input[i] = x \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\newline {i + 1} \u0026amp;\u0026amp; if input[i] = x \\newline \\ \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\newline {i + 1} \u0026amp;\u0026amp; if input[i] = x \\newline \\brace \u0026amp;\u0026amp; otherwise \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\newline {i + 1} \u0026amp;\u0026amp; if input[i] = x \\newline \\brace \u0026amp;\u0026amp; otherwise \\newline \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{lr} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\newline {i + 1} \u0026amp;\u0026amp; if input[i] = x \\newline \\brace \u0026amp;\u0026amp; otherwise \\newline \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{rl} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\newline {i + 1} \u0026amp;\u0026amp; if input[i] = x \\newline \\brace \u0026amp;\u0026amp; otherwise \\newline \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{ll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\newline {i + 1} \u0026amp;\u0026amp; if input[i] = x \\newline \\brace \u0026amp;\u0026amp; otherwise \\newline \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"},{"content":"The Call to Adventure Skip this if you\u0026rsquo;re here just for the parser generator part :)\nIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\nAnd so, I did. I got together a simple lexer and parser and made it to spit out a parse tree. But that was it. All that rage for nothing. A day or two later, I stumbled upon a Wikipedia article on parser generators (I don\u0026rsquo;t know how I got there)\nIf I had a list for all the interesting things that happened to me in the year 2025, the first entry would be the discovery of parser combinators.\nThe Fundamental Spells According to Wikipedia,\nA parser combinator is a higher-order function that accepts several parsers as input and returns a new parser as its output.\nBasically, a parser combinator is a function that takes one or more functions as parameters and returns a function combining these functions. In this context, these functions are supposed to be parsers. Parser combinators are a great tool for prototyping compilers for domain-specific tasks. More of it on later sections.\nSo, before moving to combining parsers, we need to define what a parser should be able to do. Mathematically, a parser is a function f that takes an input a recognizer x and an index i and produces an output such that:\n$$ f(input, x, i) = \\left\\lbrace \\begin{array}{lll} \\brace \u0026amp;\u0026amp; if i \\gt len(input) \\newline {i + 1} \u0026amp;\u0026amp; if input[i] = x \\newline \\brace \u0026amp;\u0026amp; otherwise \\newline \\end{array} \\right. $$\nThe Dark Arts of Parsing By functional programming standards, we should be able to return a result type type from the parser function. The naive approach might be to define result as follows:\ntype Result[T any] struct { parsedResult T remString string } type Parser[T any] interface { parse(string) (result[T], error) } This is what I thought as well. But the problem with defining Result and Parser with generics is that dealing with generics became a whole lot complex and was causing issues with the testing (handling DeepEqual was a headache on its own.) There was also a different problem: I wasn\u0026rsquo;t considering the input as a state machine. Although it wasn\u0026rsquo;t that big of a performance bottleneck (I haven\u0026rsquo;t benchmarked it against the second version) but I just didn\u0026rsquo;t like passing a string around too much. I now had two problems to deal with:\nRedefine Parser and Result Implement a state machine. A State could be defined as follows:\ntype State struct { input string offset int } This implementation now had one major advantage: a separate type gave me greater freedom. I could now define helper functions maybe add a few more features for better error handling.\n// Check if there are characters available for parsing func (s State) HasAvailableChars(n int) bool {} // Consume n characters and return func (s State) Consume(n int) (string, error) {} // Peek one char -- consume without advancing func (s State) PeekChar() (byte, error) {} // Advance n places and return the next state func (s State) Advance(n int) State {} The State API was the last thing I added to this library, but for the purpose of this blog let\u0026rsquo;s assume I defined it in the beginning. So, with the State in place, I was now left with the Result and Parser types.\ntype Result struct { parsedResult interface nextState State } type Parser func(curState State) (result, error) Having the Parser type as a function would allow the combinators to be \u0026ldquo;technically\u0026rdquo; called higher-order functions. Now, all that was left was to define some basic parsers.\n// basic char parser func CharParser(c byte) Parser { return func(curState State) (Result, error) { if curState.offset \u0026gt;= len(curState.input) { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;reached the end of input string while parsing\u0026#34;) } if curState.input[curState.offset] != c { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %c but received %c\u0026#34;, c, curState.input[curState.offset]) } return NewResult( string(c), curState.Advance(1), ), nil } } // Parses a string exactly and advances the current State. func String(s string) Parser { return func(curState State) (Result, error) { if curState.input[curState.offset:] != s { return NewResult( nil, curState, ), fmt.Errorf(\u0026#34;expected %s\u0026#34;, s) } return NewResult( s, curState.Advance(len(s)), ), nil } } Mastering the Dark Art of Parser Combinators Now that I had defined two of the most basic parsers, I started writing combinators. Here are a few of them:\n// Lazily perform OR between the left and right parsers func Or(left Parser, right Parser) Parser { return func(curState State) (Result, error) { leftRes, err := left(curState) if err != nil { curState = leftRes.nextState return right(curState) } return leftRes, nil } } // Lazily perform AND between the left and right parsers func And(left Parser, right Parser) Parser {} // Parse 0 or more occurence of the parser in the input/state machine func Many0(p Parser) Parser {} // Parse 1 or more occurence of the parser in the input/state machine func Many1(p Parser) Parser {} You might\u0026rsquo;ve noticed that there\u0026rsquo;s only two params in the Or and And combinators. It could benefit from multiple params, but as of now I haven\u0026rsquo;t changed them :(\nApart from the basic ones, there were some special combinators that I found really interesting. First was the Map combinator. Similar to other general-purpose programming languages, a Map combinator maps the output of a parser to a different function. The reason it is interesting is that it helps to convert a parsed string to a data type of our choice, which comes in handy in a lot of different ways.\nFor instance, if I had to write a parser that takes an input and gives me an integer, I would want a combinator such that:\ndigits := Or(CharParser(\u0026#39;0\u0026#39;), CharParser(\u0026#39;1\u0026#39;), ..., CharParser(\u0026#39;9\u0026#39;)) digitParser := Many0(digits) // a function that takes an array of strings and outputs an int func parseInt(d []string) (int, error) { res := \u0026#34;\u0026#34; for _, val := range d { res = res + val } return strconv.Atoi(res) } intParser := Map(digitParser, parseInt) // we need this Although we could\u0026rsquo;ve mapped it ourselves, but that would mean that we would have to repeat the same set of lines for every mapping we wanted, which violates the DRY principle. So, here\u0026rsquo;s the implementation of the Map combinator:\nfunc Map[A, B any](p Parser, mapping func(A) B) Parser { return func(curState State) (Result, error) { res, err := p(curState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( mapping(res.parsedResult.(A)), res.nextState, ), nil } } I have used generics here, because this is a sort of a workaround because Go doesn\u0026rsquo;t support parameterized methods.\nThe next few were equally interesting:\nBetween combinator. This combinator matches a parser surrounded by two others. This would later help us in matching content within parentheses, braces, or quotation marks. Sequence combinator. This combinator sequentially passes the state from one parser to another, and returns a union of the parsed results if all the parsers pass. Lazy combinator. This combinator is perhaps the most important of all the combinators. It defers the creation of a parser unless required. It plays a pivotal role in parsing recursively defined parsers (more on that later). // Lazy parsing with memoization func Lazy(f func() Parser) Parser { var memo Parser return func(curState State) (Result, error) { if memo == nil { memo = f() } return memo(curState) } } // Parse the content between open and close parser func Between(open, content, close Parser) Parser { return func(curState State) (Result, error) { openRes, err := open(curState) if err != nil { return NewResult( nil, curState, ), err } contentRes, err := content(openRes.nextState) if err != nil { return NewResult( nil, curState, ), err } closeRes, err := close(contentRes.nextState) if err != nil { return NewResult( nil, curState, ), err } return NewResult( contentRes.parsedResult, closeRes.nextState, ), nil } } // Sequentially parse parsers func Seq(parsers ...Parser) Parser { return func(curState State) (Result, error) { var res []interface{} next := curState for _, parser := range parsers { x, err := parser(next) if err != nil { return NewResult( nil, curState, // fallback to the initial State ), err } res = append(res, x.parsedResult) next = x.nextState } return NewResult( res, next, ), nil } } Phew! That was indeed a LOT of work. But I was only just halfway there. The final boss was waiting for me.\nPractical Dark Arts Defense Now that I had all this set up, it was time for me to make a small DSL. For me, it was going to be a small JSON parser. A JSON can appear in various shapes:\nNumbers Strings Arrays The trickiest part - handling arrays within arrays - could now be handled easily with the help of our favorite Lazy combinator. Here\u0026rsquo;s how I crafted it: func jsonString() parser.Parser { stringChar := func() parser.Parser { return func(curState parser.State) (parser.Result, error) { c, err := curState.PeekChar() if err != nil { return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected end of input\u0026#34;) } if c != \u0026#39;\u0026#34;\u0026#39; \u0026amp;\u0026amp; c != \u0026#39;\\\\\u0026#39; { return parser.NewResult( string(c), curState.Advance(1), ), nil } return parser.NewResult(nil, curState), fmt.Errorf(\u0026#34;unexpected character %s\u0026#34;, string(c)) } } return parser.Map( parser.Between( parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), parser.Many0(stringChar()), parser.CharParser(\u0026#39;\u0026#34;\u0026#39;), ), func(chars interface{}) string { var sb strings.Builder for _, c := range chars.([]interface{}) { sb.WriteString(c.(string)) } return sb.String() }, ) } // parse a json array func jsonArray() parser.Parser { return parser.Map( parser.Between( parser.Seq(parser.CharParser(\u0026#39;[\u0026#39;), whitespace()), parser.Many0( parser.Seq( parser.Lazy(func() parser.Parser { return jsonValue }), parser.Many0( parser.Seq( parser.CharParser(\u0026#39;,\u0026#39;), whitespace(), parser.Lazy(func() parser.Parser { return jsonValue }), ), ), ), ), parser.Seq(whitespace(), parser.CharParser(\u0026#39;]\u0026#39;)), ), func(val interface{}) []interface{} { if len(val.([]interface{})) == 0 { return []interface{}{} } result := make([]interface{}, 0) seqResults := val.([]interface{}) result = append(result, seqResults[0].([]interface{})[0]) // items of the second seq in the form [[\u0026#39;,\u0026#39;, \u0026#39; \u0026#39;, jsonvalue], ...] restItems := seqResults[0].([]interface{})[1].([]interface{}) for _, item := range restItems { itemSeq := item.([]interface{}) result = append(result, itemSeq[2]) } return result }, ) } // parse the JSON func ParseJSON(input string) (interface{}, error) { jsonValue = parser.Or( parser.Or( jsonString(), jsonNumber(), ), parser.Lazy(jsonArray), ) res, err := jsonValue(parser.NewState(input, 0)) fmt.Println(res) if err != nil { return nil, err } return res, nil } func main() { // Test cases inputs := []string{ `123`, `\u0026#34;Hello World\u0026#34;`, `[ 1, 2, \u0026#34;Hello World\u0026#34; ]`, `[ 1, 2, [ 1, 3 ] ]`, `[ ]`, } fmt.Printf(\u0026#34;Test cases: \\n %s\u0026#34;, inputs) for _, input := range inputs { result, err := ParseJSON(input) if err != nil { fmt.Printf(\u0026#34;Error parsing %s: %v\\n\u0026#34;, input, err) continue } fmt.Printf(\u0026#34;Successfully parsed %s: %v\\n\u0026#34;, input, result) } } Beyond the Chamber Parser combinators, although simple on their own, are really powerful tools. As Dumbledore might say, \u0026ldquo;It is not our parsing abilities that make us good programmers, but how we combine them.\u0026rdquo;\nBut, as the saying goes, with great power comes great responsibility. Parser combinators are only used in domain-specific tasks that aren\u0026rsquo;t too complex. This is because general-purpose languages are complex and they benefit from the separation of concerns provided by having a separate lexer and parser.\nLinks Parser Combinator Library JSON Parser Implementation Bonus: Lazy Evaluation- Wikipedia ","permalink":"http://localhost:1313/posts/parser-combinators/","summary":"\u003ch1 id=\"the-call-to-adventure\"\u003eThe Call to Adventure\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003e\u003c!-- raw HTML omitted --\u003eSkip this if you\u0026rsquo;re here just for the parser generator part :)\u003c!-- raw HTML omitted --\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf I had a list of disappointments for the year 2025, the first entry would be my college not offering the Compiler Design course in 6th semester. I mean, why shouldn\u0026rsquo;t they? So what if they\u0026rsquo;ve clearly stated in the scheme that they\u0026rsquo;ll be offering it in the 8th semester? Unable to digest the fact that I wasn\u0026rsquo;t in 8th semester already, I decided to do something myself. And so, I started learning how to make my own compiler. To my surprise, it wasn\u0026rsquo;t an easy task. Most \u0026ldquo;tutorials\u0026rdquo; on compiler design just sort of skip on the most basic phase: building a lexer and a parser. For the sake of \u0026ldquo;simplicity,\u0026rdquo; they instead focus on more important tasks at hand. It was indeed disheartening. I mean, what\u0026rsquo;s the point of learning something if I don\u0026rsquo;t even know how it is supposed to work.\u003c/p\u003e","title":"Parser Combinators"}]